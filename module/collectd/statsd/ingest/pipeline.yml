description: Pipeline for parsing collectd statsd logs
processors:
- set:
    field: event.ingested
    value: '{{_ingest.timestamp}}'
- grok:
    field: message
    patterns:
      - '^\[%{TIMESTAMP_ISO8601:collectd.statsd.timestamp}\]%{SPACE}write_log values:%{SPACE}%{NOTSPACE:collectd.statsd.key}%{SPACE}%{NOTSPACE:collectd.statsd.value}%{SPACE}%{NOTSPACE:collectd.statsd.timestamp_seconds}$'
      - '^\[%{TIMESTAMP_ISO8601:collectd.statsd.timestamp}\]%{SPACE}%{NOTSPACE:collectd.statsd.message}'
    pattern_definitions:
      GREEDYMULTILINE: |-
        (.|
        )*
    ignore_missing: true
- date:
    if: ctx.event.timezone == null
    field: collectd.statsd.timestamp
    target_field: '@timestamp'
    formats:
    - yyyy-MM-dd HH:mm:ss
    on_failure:
    - append:
        field: error.message
        value: '{{ _ingest.on_failure_message }}'
    - append:
        field: error.grok
        value: true
- date:
    if: ctx.event.timezone != null
    field: collectd.statsd.timestamp
    target_field: '@timestamp'
    formats:
    - yyyy-MM-dd HH:mm:ss
    timezone: '{{ event.timezone }}'
    on_failure:
    - append:
        field: error.message
        value: '{{ _ingest.on_failure_message }}'
- remove:
    field: collectd.statsd.timestamp
- convert:
    ignore_missing: true
    field: collectd.statsd.value
    type: float
- convert:
    ignore_missing: true
    field: collectd.statsd.timestamp_seconds
    type: long
- set:
    field: event.kind
    value: event
on_failure:
- set:
    field: error.message
    value: '{{ _ingest.on_failure_message }}'
